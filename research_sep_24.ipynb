{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fo2VcL-hUjTx",
      "metadata": {
        "id": "fo2VcL-hUjTx"
      },
      "source": [
        "# Code 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "heut6rQLf1Cc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heut6rQLf1Cc",
        "outputId": "be1a3d94-872c-428e-a94c-ed4c4b03161b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Set Up Environment and Install Dependencies\n",
        "!pip install -q pandas numpy scikit-learn nltk textblob spacy transformers sentence-transformers\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from textblob import TextBlob\n",
        "import spacy\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.sparse import hstack\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "print(\"Environment setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "qSIq1WDTpm-Z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSIq1WDTpm-Z",
        "outputId": "c3d953d2-ebdf-4642-b6fa-22927ea321f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset loaded:\n",
            "   fold_id cv_tag  html_id  sent_id  \\\n",
            "0        0  cv000    29590        0   \n",
            "1        0  cv000    29590        1   \n",
            "2        0  cv000    29590        2   \n",
            "3        0  cv000    29590        3   \n",
            "4        0  cv000    29590        4   \n",
            "\n",
            "                                                text  tag  \n",
            "0  films adapted from comic books have had plenty...  pos  \n",
            "1  for starters , it was created by alan moore ( ...  pos  \n",
            "2  to say moore and campbell thoroughly researche...  pos  \n",
            "3  the book ( or \" graphic novel , \" if you will ...  pos  \n",
            "4  in other words , don't dismiss this film becau...  pos  \n",
            "Shape: (64720, 6)\n",
            "Sentiment distribution: tag\n",
            "pos    32937\n",
            "neg    31783\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Mount Google Drive and Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load dataset (adjust path if needed)\n",
        "data_path = '/content/drive/MyDrive/Dataset/movie_review.csv'  # Update to your path\n",
        "df = pd.read_csv(data_path)\n",
        "\n",
        "print(\"Dataset loaded:\")\n",
        "print(df.head())\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(\"Sentiment distribution:\", df['tag'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "KVdvYCXGp9BI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVdvYCXGp9BI",
        "outputId": "60f456ba-9291-4449-dec9-0212f6b658fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded classes: ['neg' 'pos']\n",
            "Data prepared. Train shape: (51776,) Test shape: (12944,)\n",
            "Train set issue distribution:\n",
            " issue_encoded\n",
            "1    26364\n",
            "0    25412\n",
            "Name: count, dtype: int64\n",
            "Test set issue distribution:\n",
            " issue_encoded\n",
            "1    6573\n",
            "0    6371\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Select Relevant Columns and Preprocess\n",
        "# Keep only 'Issue' and 'Sub-issue'\n",
        "df = df[['text', 'tag']]\n",
        "\n",
        "# Fill NaN in 'Sub-issue' with empty string to avoid errors\n",
        "df['text'] = df['text'].fillna(\"\")\n",
        "df['tag'] = df['tag'].fillna(\"\")\n",
        "\n",
        "# Example: If you want to classify based on 'Issue' only\n",
        "# Use 'Issue' as label\n",
        "le = LabelEncoder()\n",
        "df['issue_encoded'] = le.fit_transform(df['tag'])\n",
        "print(\"Encoded classes:\", le.classes_)\n",
        "\n",
        "# Train-test split (80/20)\n",
        "X = df['text']\n",
        "y = df['issue_encoded']\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Data prepared. Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
        "print(\"Train set issue distribution:\\n\", pd.Series(y_train).value_counts())\n",
        "print(\"Test set issue distribution:\\n\", pd.Series(y_test).value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "SuyVVlm40QcX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuyVVlm40QcX",
        "outputId": "accd0142-4200-4c62-dbc5-694084f3568a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rule-Based Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.53      0.44      0.48      6371\n",
            "         pos       0.53      0.62      0.57      6573\n",
            "\n",
            "    accuracy                           0.53     12944\n",
            "   macro avg       0.53      0.53      0.53     12944\n",
            "weighted avg       0.53      0.53      0.53     12944\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Rule-Based Model with Enhanced Negation Handling\n",
        "def rule_based_sentiment(text):\n",
        "    # VADER sentiment\n",
        "    vader_score = sia.polarity_scores(text)['compound']\n",
        "\n",
        "    # Enhance with spaCy negation detection\n",
        "    doc = nlp(text)\n",
        "    negation = any(token.dep_ == 'neg' for token in doc)\n",
        "\n",
        "    # Adjust thresholds and handle negations\n",
        "    if negation and vader_score > 0:\n",
        "        return 0  # Flip to Negative if negation detected\n",
        "    elif vader_score > 0.1:  # Tighter threshold for Positive\n",
        "        return 1  # Positive (changed from 2)\n",
        "    elif vader_score < -0.1:  # Tighter threshold for Negative\n",
        "        return 0  # Negative\n",
        "    else:\n",
        "        # Since there's no 'Neutral' in this dataset, we'll assign close scores\n",
        "        # to the closest sentiment or re-evaluate. For now, assign to the dominant class if no strong sentiment.\n",
        "        # This part might need adjustment based on how 'neutral' should be handled in a binary classification context.\n",
        "        # Given the dataset only has 'Negative' and 'Positive', we'll force a binary output.\n",
        "        return 1 if vader_score >= 0 else 0\n",
        "\n",
        "\n",
        "# Apply to test set\n",
        "y_pred_rule = [rule_based_sentiment(text) for text in X_test]\n",
        "\n",
        "# Evaluate Rule-Based\n",
        "print(\"Rule-Based Evaluation:\")\n",
        "# Ensure target_names matches the actual classes present\n",
        "print(classification_report(y_test, y_pred_rule, target_names=le.classes_, zero_division=0))\n",
        "acc_rule = accuracy_score(y_test, y_pred_rule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-KyR31py2pkC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KyR31py2pkC",
        "outputId": "5f8c81e3-2a77-4c60-fc8c-7ac4b8369fa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.63      0.63      0.63      6371\n",
            "         pos       0.64      0.64      0.64      6573\n",
            "\n",
            "    accuracy                           0.64     12944\n",
            "   macro avg       0.64      0.64      0.64     12944\n",
            "weighted avg       0.64      0.64      0.64     12944\n",
            "\n",
            "SVM Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.63      0.64      0.63      6371\n",
            "         pos       0.64      0.63      0.64      6573\n",
            "\n",
            "    accuracy                           0.63     12944\n",
            "   macro avg       0.63      0.63      0.63     12944\n",
            "weighted avg       0.63      0.63      0.63     12944\n",
            "\n",
            "Random Forest Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.68      0.20      0.31      6371\n",
            "         pos       0.54      0.91      0.68      6573\n",
            "\n",
            "    accuracy                           0.56     12944\n",
            "   macro avg       0.61      0.56      0.49     12944\n",
            "weighted avg       0.61      0.56      0.50     12944\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 5 & 6: ML Models with N-gram Features (TF-IDF with 1-3 grams), Evaluation\n",
        "# Vectorizer for n-grams (reduced features to prevent overfitting)\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 3), stop_words='english', max_features=2000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Model 1: Logistic Regression (with regularization)\n",
        "lr_model = LogisticRegression(max_iter=1000, C=0.5)\n",
        "lr_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
        "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
        "print(\"Logistic Regression Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_lr, target_names=le.classes_, zero_division=0))\n",
        "\n",
        "# Model 2: SVM\n",
        "svm_model = SVC(kernel='linear', C=0.5)\n",
        "svm_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
        "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(\"SVM Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_svm, target_names=le.classes_, zero_division=0))\n",
        "\n",
        "# Model 3: Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
        "rf_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
        "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Random Forest Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_rf, target_names=le.classes_, zero_division=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Separate Testing"
      ],
      "metadata": {
        "id": "ruRrbK7RxPDc"
      },
      "id": "ruRrbK7RxPDc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30062901",
      "metadata": {
        "id": "30062901"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Step 5 & 6: ML Models with N-gram Features (TF-IDF with 1-2 grams), Evaluation\n",
        "# Improved Vectorizer: wider n-grams, higher features, min_df to reduce noise\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words='english', max_features=5000, min_df=2)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Model 1: Logistic Regression with hyperparameter tuning\n",
        "lr_param_grid = {'C': [0.1, 0.5, 1.0, 5.0]}  # Tune regularization strength\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_grid = GridSearchCV(lr_model, lr_param_grid, cv=3, scoring='accuracy')\n",
        "lr_grid.fit(X_train_tfidf, y_train)\n",
        "y_pred_lr = lr_grid.best_estimator_.predict(X_test_tfidf)\n",
        "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
        "print(\"Logistic Regression Best Params:\", lr_grid.best_params_)\n",
        "print(\"Logistic Regression Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_lr, target_names=le.classes_, zero_division=0))\n",
        "\n",
        "# Model 2: SVM with hyperparameter tuning\n",
        "svm_param_grid = {'C': [0.1, 0.5, 1.0, 5.0]}  # Tune penalty\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_grid = GridSearchCV(svm_model, svm_param_grid, cv=3, scoring='accuracy')\n",
        "svm_grid.fit(X_train_tfidf, y_train)\n",
        "y_pred_svm = svm_grid.best_estimator_.predict(X_test_tfidf)\n",
        "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(\"SVM Best Params:\", svm_grid.best_params_)\n",
        "print(\"SVM Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_svm, target_names=le.classes_, zero_division=0))\n",
        "\n",
        "# Model 3: Random Forest with improved params and tuning\n",
        "rf_param_grid = {'n_estimators': [100, 200], 'max_depth': [10, 20, None]}  # Tune depth and trees\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_grid = GridSearchCV(rf_model, rf_param_grid, cv=3, scoring='accuracy')\n",
        "rf_grid.fit(X_train_tfidf, y_train)\n",
        "y_pred_rf = rf_grid.best_estimator_.predict(X_test_tfidf)\n",
        "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Random Forest Best Params:\", rf_grid.best_params_)\n",
        "print(\"Random Forest Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_rf, target_names=le.classes_, zero_division=0))\n",
        "\n",
        "# New Model 4: Multinomial Naive Bayes (great for TF-IDF text classification)\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "nb_model = MultinomialNB(alpha=0.5)  # Smoothing parameter; can tune if needed\n",
        "nb_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
        "acc_nb = accuracy_score(y_test, y_pred_nb)\n",
        "print(\"Multinomial Naive Bayes Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_nb, target_names=le.classes_, zero_division=0))\n",
        "\n",
        "# Optional: Inspect top features from RF (for debugging/improvement)\n",
        "importances = rf_grid.best_estimator_.feature_importances_\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "top_features = sorted(zip(importances, feature_names), reverse=True)[:10]\n",
        "print(\"Top 10 Features by Importance:\", top_features)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Step 5 & 6: ML Models with N-gram Features (TF-IDF with 1-2 grams), Evaluation\n",
        "# Improved Vectorizer: wider n-grams, higher features, min_df to reduce noise\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words='english', max_features=5000, min_df=2)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "zKDF7s2Ozm7N"
      },
      "id": "zKDF7s2Ozm7N",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1: Logistic Regression with hyperparameter tuning c = 0.1\n",
        "lr_param_grid = {'C': [0.1]}  # Tune regularization strength\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_grid = GridSearchCV(lr_model, lr_param_grid, cv=3, scoring='accuracy')\n",
        "lr_grid.fit(X_train_tfidf, y_train)\n",
        "y_pred_lr = lr_grid.best_estimator_.predict(X_test_tfidf)\n",
        "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
        "print(\"Logistic Regression Best Params:\", lr_grid.best_params_)\n",
        "print(\"Logistic Regression Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_lr, target_names=le.classes_, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQaUF6M4xdyx",
        "outputId": "373d49bf-b2ee-4c05-e64c-e5870cfc22de"
      },
      "id": "HQaUF6M4xdyx",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Best Params: {'C': 0.1}\n",
            "Logistic Regression Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.65      0.62      0.63      6371\n",
            "         pos       0.65      0.68      0.67      6573\n",
            "\n",
            "    accuracy                           0.65     12944\n",
            "   macro avg       0.65      0.65      0.65     12944\n",
            "weighted avg       0.65      0.65      0.65     12944\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1: Logistic Regression with hyperparameter tuning c = 0.5\n",
        "lr_param_grid = {'C': [0.5]}  # Tune regularization strength\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_grid = GridSearchCV(lr_model, lr_param_grid, cv=3, scoring='accuracy')\n",
        "lr_grid.fit(X_train_tfidf, y_train)\n",
        "y_pred_lr = lr_grid.best_estimator_.predict(X_test_tfidf)\n",
        "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
        "print(\"Logistic Regression Best Params:\", lr_grid.best_params_)\n",
        "print(\"Logistic Regression Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_lr, target_names=le.classes_, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNBdwOoOxsAg",
        "outputId": "45afa086-712f-4e6e-e6eb-bc33baf9f248"
      },
      "id": "UNBdwOoOxsAg",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Best Params: {'C': 0.5}\n",
            "Logistic Regression Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.66      0.65      0.65      6371\n",
            "         pos       0.66      0.67      0.67      6573\n",
            "\n",
            "    accuracy                           0.66     12944\n",
            "   macro avg       0.66      0.66      0.66     12944\n",
            "weighted avg       0.66      0.66      0.66     12944\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1: Logistic Regression with hyperparameter tuning c = 1.0\n",
        "lr_param_grid = {'C': [1.0]}  # Tune regularization strength\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_grid = GridSearchCV(lr_model, lr_param_grid, cv=3, scoring='accuracy')\n",
        "lr_grid.fit(X_train_tfidf, y_train)\n",
        "y_pred_lr = lr_grid.best_estimator_.predict(X_test_tfidf)\n",
        "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
        "print(\"Logistic Regression Best Params:\", lr_grid.best_params_)\n",
        "print(\"Logistic Regression Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_lr, target_names=le.classes_, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4n5c0X2xu5s",
        "outputId": "b51dd02f-41c0-43db-ee13-4e41e7dc0a84"
      },
      "id": "H4n5c0X2xu5s",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Best Params: {'C': 1.0}\n",
            "Logistic Regression Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.65      0.65      0.65      6371\n",
            "         pos       0.67      0.67      0.67      6573\n",
            "\n",
            "    accuracy                           0.66     12944\n",
            "   macro avg       0.66      0.66      0.66     12944\n",
            "weighted avg       0.66      0.66      0.66     12944\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1: Logistic Regression with hyperparameter tuning c = 5.0\n",
        "lr_param_grid = {'C': [5.0]}  # Tune regularization strength\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_grid = GridSearchCV(lr_model, lr_param_grid, cv=3, scoring='accuracy')\n",
        "lr_grid.fit(X_train_tfidf, y_train)\n",
        "y_pred_lr = lr_grid.best_estimator_.predict(X_test_tfidf)\n",
        "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
        "print(\"Logistic Regression Best Params:\", lr_grid.best_params_)\n",
        "print(\"Logistic Regression Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_lr, target_names=le.classes_, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZRgCNHwxxKS",
        "outputId": "4993238e-3a72-4461-d414-da5b59cc90ed"
      },
      "id": "sZRgCNHwxxKS",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Best Params: {'C': 5.0}\n",
            "Logistic Regression Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.65      0.66      0.65      6371\n",
            "         pos       0.66      0.66      0.66      6573\n",
            "\n",
            "    accuracy                           0.66     12944\n",
            "   macro avg       0.66      0.66      0.66     12944\n",
            "weighted avg       0.66      0.66      0.66     12944\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1: Logistic Regression with hyperparameter tuning c = 10.0\n",
        "lr_param_grid = {'C': [10.0]}  # Tune regularization strength\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_grid = GridSearchCV(lr_model, lr_param_grid, cv=3, scoring='accuracy')\n",
        "lr_grid.fit(X_train_tfidf, y_train)\n",
        "y_pred_lr = lr_grid.best_estimator_.predict(X_test_tfidf)\n",
        "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
        "print(\"Logistic Regression Best Params:\", lr_grid.best_params_)\n",
        "print(\"Logistic Regression Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_lr, target_names=le.classes_, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WggEcK2lzxeU",
        "outputId": "814eee86-46f1-4a8f-851f-9a3c894bb44e"
      },
      "id": "WggEcK2lzxeU",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Best Params: {'C': 10.0}\n",
            "Logistic Regression Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.65      0.66      0.65      6371\n",
            "         pos       0.67      0.66      0.66      6573\n",
            "\n",
            "    accuracy                           0.66     12944\n",
            "   macro avg       0.66      0.66      0.66     12944\n",
            "weighted avg       0.66      0.66      0.66     12944\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2: SVM with hyperparameter tuning c = 0.1\n",
        "svm_param_grid = {'C': [0.1]}  # Tune penalty\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_grid = GridSearchCV(svm_model, svm_param_grid, cv=3, scoring='accuracy')\n",
        "svm_grid.fit(X_train_tfidf, y_train)\n",
        "y_pred_svm = svm_grid.best_estimator_.predict(X_test_tfidf)\n",
        "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(\"SVM Best Params:\", svm_grid.best_params_)\n",
        "print(\"SVM Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_svm, target_names=le.classes_, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IesAS8RHz60P",
        "outputId": "d3e3ddeb-89e7-434f-94ac-cee87649286f"
      },
      "id": "IesAS8RHz60P",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Best Params: {'C': 0.1}\n",
            "SVM Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.66      0.61      0.63      6371\n",
            "         pos       0.65      0.69      0.67      6573\n",
            "\n",
            "    accuracy                           0.65     12944\n",
            "   macro avg       0.65      0.65      0.65     12944\n",
            "weighted avg       0.65      0.65      0.65     12944\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2: SVM with hyperparameter tuning c = 0.5\n",
        "svm_param_grid = {'C': [0.5]}  # Tune penalty\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_grid = GridSearchCV(svm_model, svm_param_grid, cv=3, scoring='accuracy')\n",
        "svm_grid.fit(X_train_tfidf, y_train)\n",
        "y_pred_svm = svm_grid.best_estimator_.predict(X_test_tfidf)\n",
        "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(\"SVM Best Params:\", svm_grid.best_params_)\n",
        "print(\"SVM Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_svm, target_names=le.classes_, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moDVn6pR0AwW",
        "outputId": "4360d19a-0d89-4241-f443-04ada828338c"
      },
      "id": "moDVn6pR0AwW",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Best Params: {'C': 0.5}\n",
            "SVM Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.65      0.66      0.66      6371\n",
            "         pos       0.67      0.66      0.66      6573\n",
            "\n",
            "    accuracy                           0.66     12944\n",
            "   macro avg       0.66      0.66      0.66     12944\n",
            "weighted avg       0.66      0.66      0.66     12944\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2: SVM with hyperparameter tuning c = 1.0\n",
        "svm_param_grid = {'C': [1.0]}  # Tune penalty\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_grid = GridSearchCV(svm_model, svm_param_grid, cv=3, scoring='accuracy')\n",
        "svm_grid.fit(X_train_tfidf, y_train)\n",
        "y_pred_svm = svm_grid.best_estimator_.predict(X_test_tfidf)\n",
        "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(\"SVM Best Params:\", svm_grid.best_params_)\n",
        "print(\"SVM Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_svm, target_names=le.classes_, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P876tt1y0CyM",
        "outputId": "87a41ab7-5156-4322-ae2e-9459032dc105"
      },
      "id": "P876tt1y0CyM",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Best Params: {'C': 1.0}\n",
            "SVM Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.65      0.66      0.66      6371\n",
            "         pos       0.67      0.65      0.66      6573\n",
            "\n",
            "    accuracy                           0.66     12944\n",
            "   macro avg       0.66      0.66      0.66     12944\n",
            "weighted avg       0.66      0.66      0.66     12944\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2: SVM with hyperparameter tuning c = 5.0\n",
        "svm_param_grid = {'C': [5.0]}  # Tune penalty\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_grid = GridSearchCV(svm_model, svm_param_grid, cv=3, scoring='accuracy')\n",
        "svm_grid.fit(X_train_tfidf, y_train)\n",
        "y_pred_svm = svm_grid.best_estimator_.predict(X_test_tfidf)\n",
        "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(\"SVM Best Params:\", svm_grid.best_params_)\n",
        "print(\"SVM Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_svm, target_names=le.classes_, zero_division=0))"
      ],
      "metadata": {
        "id": "qwI5X69a0H04"
      },
      "id": "qwI5X69a0H04",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2: SVM with hyperparameter tuning c = 10.0\n",
        "svm_param_grid = {'C': [10.0]}  # Tune penalty\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_grid = GridSearchCV(svm_model, svm_param_grid, cv=3, scoring='accuracy')\n",
        "svm_grid.fit(X_train_tfidf, y_train)\n",
        "y_pred_svm = svm_grid.best_estimator_.predict(X_test_tfidf)\n",
        "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
        "print(\"SVM Best Params:\", svm_grid.best_params_)\n",
        "print(\"SVM Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_svm, target_names=le.classes_, zero_division=0))"
      ],
      "metadata": {
        "id": "v2NZDYPX0KzX"
      },
      "id": "v2NZDYPX0KzX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 3: Random Forest with improved params and tuning\n",
        "rf_param_grid = {'n_estimators': [100, 200], 'max_depth': [10, 20, None]}  # Tune depth and trees\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_grid = GridSearchCV(rf_model, rf_param_grid, cv=3, scoring='accuracy')\n",
        "rf_grid.fit(X_train_tfidf, y_train)\n",
        "y_pred_rf = rf_grid.best_estimator_.predict(X_test_tfidf)\n",
        "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(\"Random Forest Best Params:\", rf_grid.best_params_)\n",
        "print(\"Random Forest Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_rf, target_names=le.classes_, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxGxAJTO0adf",
        "outputId": "3f887381-646e-4ef5-d16b-8e09250e981d"
      },
      "id": "FxGxAJTO0adf",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Best Params: {'max_depth': None, 'n_estimators': 200}\n",
            "Random Forest Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.63      0.63      0.63      6371\n",
            "         pos       0.64      0.65      0.65      6573\n",
            "\n",
            "    accuracy                           0.64     12944\n",
            "   macro avg       0.64      0.64      0.64     12944\n",
            "weighted avg       0.64      0.64      0.64     12944\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rJFS9sa84HxK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJFS9sa84HxK",
        "outputId": "976c2fb5-c233-4ac4-f741-0d39604c4d7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hybrid Model Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.63      0.62      0.63      6371\n",
            "         pos       0.64      0.64      0.64      6573\n",
            "\n",
            "    accuracy                           0.63     12944\n",
            "   macro avg       0.63      0.63      0.63     12944\n",
            "weighted avg       0.63      0.63      0.63     12944\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Step 7: Hybrid Approach (Combine Rule-Based Scores with ML Features)\n",
        "rule_scores_train = np.array([sia.polarity_scores(text)['compound'] for text in X_train]).reshape(-1, 1)\n",
        "rule_scores_test = np.array([sia.polarity_scores(text)['compound'] for text in X_test]).reshape(-1, 1)\n",
        "\n",
        "# Combine TF-IDF with rule-based scores\n",
        "X_train_hybrid = hstack((X_train_tfidf, rule_scores_train))\n",
        "X_test_hybrid = hstack((X_test_tfidf, rule_scores_test))\n",
        "\n",
        "# Train Hybrid on Logistic Regression\n",
        "hybrid_model = LogisticRegression(max_iter=1000, C=0.5)\n",
        "hybrid_model.fit(X_train_hybrid, y_train)\n",
        "y_pred_hybrid = hybrid_model.predict(X_test_hybrid)\n",
        "acc_hybrid = accuracy_score(y_test, y_pred_hybrid)\n",
        "print(\"Hybrid Model Evaluation:\")\n",
        "print(classification_report(y_test, y_pred_hybrid, target_names=le.classes_, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Bh7tMiVK4P97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "Bh7tMiVK4P97",
        "outputId": "2a5b869b-36f0-4dfa-ec48-8b5de5af8b77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Comparison:\n",
            "                 Model  Accuracy  Precision (macro)  Recall (macro)  \\\n",
            "0           Rule-Based  0.531211           0.530824        0.529773   \n",
            "1  Logistic Regression  0.635893           0.635790        0.635767   \n",
            "2                  SVM  0.634734           0.634743        0.634776   \n",
            "3        Random Forest  0.560878           0.611025        0.555366   \n",
            "4               Hybrid  0.632726           0.632624        0.632605   \n",
            "\n",
            "   F1-Score (macro)  \n",
            "0          0.526435  \n",
            "1          0.635775  \n",
            "2          0.634715  \n",
            "3          0.494711  \n",
            "4          0.632612  \n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Step 8: Compare All Models\n",
        "results = {\n",
        "    'Model': ['Rule-Based', 'Logistic Regression', 'SVM', 'Random Forest', 'Hybrid'],\n",
        "    'Accuracy': [acc_rule, acc_lr, acc_svm, acc_rf, acc_hybrid],\n",
        "    'Precision (macro)': [precision_score(y_test, y_pred_rule, average='macro', zero_division=0),\n",
        "                         precision_score(y_test, y_pred_lr, average='macro', zero_division=0),\n",
        "                         precision_score(y_test, y_pred_svm, average='macro', zero_division=0),\n",
        "                         precision_score(y_test, y_pred_rf, average='macro', zero_division=0),\n",
        "                         precision_score(y_test, y_pred_hybrid, average='macro', zero_division=0)],\n",
        "    'Recall (macro)': [recall_score(y_test, y_pred_rule, average='macro', zero_division=0),\n",
        "                       recall_score(y_test, y_pred_lr, average='macro', zero_division=0),\n",
        "                       recall_score(y_test, y_pred_svm, average='macro', zero_division=0),\n",
        "                       recall_score(y_test, y_pred_rf, average='macro', zero_division=0),\n",
        "                       recall_score(y_test, y_pred_hybrid, average='macro', zero_division=0)],\n",
        "    'F1-Score (macro)': [f1_score(y_test, y_pred_rule, average='macro', zero_division=0),\n",
        "                         f1_score(y_test, y_pred_lr, average='macro', zero_division=0),\n",
        "                         f1_score(y_test, y_pred_svm, average='macro', zero_division=0),\n",
        "                         f1_score(y_test, y_pred_rf, average='macro', zero_division=0),\n",
        "                         f1_score(y_test, y_pred_hybrid, average='macro', zero_division=0)]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"Model Comparison:\")\n",
        "print(results_df)\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(results_df['Model'], results_df['Accuracy'])\n",
        "plt.xlabel('Models')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TnZJOQm74WMz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnZJOQm74WMz",
        "outputId": "99ea1382-f5a8-42f7-9554-b4b7b4b562f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Review: The battery life is amazing, lasts all day!\n",
            "{'Rule-Based': 'pos', 'Logistic Regression': 'pos', 'SVM': 'pos', 'Random Forest': 'pos', 'Hybrid': 'pos'}\n",
            "\n",
            "Review: This product is terrible, broke after a week.\n",
            "{'Rule-Based': 'neg', 'Logistic Regression': 'neg', 'SVM': 'neg', 'Random Forest': 'neg', 'Hybrid': 'neg'}\n",
            "\n",
            "Review: It's okay, nothing special but works fine.\n",
            "{'Rule-Based': 'pos', 'Logistic Regression': 'pos', 'SVM': 'pos', 'Random Forest': 'pos', 'Hybrid': 'pos'}\n",
            "\n",
            "Review: False statements or representation\n",
            "{'Rule-Based': 'pos', 'Logistic Regression': 'neg', 'SVM': 'neg', 'Random Forest': 'pos', 'Hybrid': 'neg'}\n"
          ]
        }
      ],
      "source": [
        "# Step 9: Input Different Reviews and Compare Results\n",
        "def predict_sentiment(new_review):\n",
        "    tfidf_vec = vectorizer.transform([new_review])\n",
        "    rule_score = np.array([sia.polarity_scores(new_review)['compound']]).reshape(-1, 1)\n",
        "    hybrid_vec = hstack((tfidf_vec, rule_score))\n",
        "\n",
        "    rule_pred = rule_based_sentiment(new_review)\n",
        "    lr_pred = lr_model.predict(tfidf_vec)[0]\n",
        "    svm_pred = svm_model.predict(tfidf_vec)[0]\n",
        "    rf_pred = rf_model.predict(tfidf_vec)[0]\n",
        "    hybrid_pred = hybrid_model.predict(hybrid_vec)[0]\n",
        "\n",
        "    # Decode labels - ensure inverse_transform is called with valid predicted labels\n",
        "    # The models might predict 0 or 1, which correspond to 'Negative' and 'Positive'\n",
        "    preds = {\n",
        "        'Rule-Based': le.inverse_transform([rule_pred])[0],\n",
        "        'Logistic Regression': le.inverse_transform([lr_pred])[0],\n",
        "        'SVM': le.inverse_transform([svm_pred])[0],\n",
        "        'Random Forest': le.inverse_transform([rf_pred])[0],\n",
        "        'Hybrid': le.inverse_transform([hybrid_pred])[0]\n",
        "    }\n",
        "    return preds\n",
        "\n",
        "# Test new reviews\n",
        "new_reviews = [\n",
        "    \"The battery life is amazing, lasts all day!\",\n",
        "    \"This product is terrible, broke after a week.\",\n",
        "    \"It's okay, nothing special but works fine.\" ,\n",
        "    \"False statements or representation\"\n",
        "]\n",
        "\n",
        "for review in new_reviews:\n",
        "    print(f\"\\nReview: {review}\")\n",
        "    print(predict_sentiment(review))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}